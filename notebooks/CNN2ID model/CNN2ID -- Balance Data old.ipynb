{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN2ID基于CNN的网络攻击检测"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "import sys\n",
    "sys.path.append('../..')\n",
    "\n",
    "from logger import setup_logging\n",
    "from models import MLP\n",
    "from utils import (\n",
    "    dataset,\n",
    "    test,\n",
    "    train,\n",
    "    train_copy,\n",
    "    utils,\n",
    "    visualisation\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "LOG_CONFIG_PATH = os.path.join(os.path.abspath(\"../..\"), \"logger\", \"logger_config.json\")\n",
    "LOG_DIR   = os.path.join(os.path.abspath(\"../..\"), \"logs\")\n",
    "DATA_DIR  = os.path.join(os.path.abspath(\"../..\"), \"data\")\n",
    "IMAGE_DIR = os.path.join(os.path.abspath(\"../..\"), \"images\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "check GPU is available?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n"
     ]
    }
   ],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print('Using {} device'.format(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# instances in training set:  140000\n",
      "# instances in validation set:  485146\n",
      "# instances in testing set:  485145\n"
     ]
    }
   ],
   "source": [
    "# Get the datasets\n",
    "train_data, val_data, test_data = dataset.get_dataset(data_path=DATA_DIR, balanced=True)\n",
    "\n",
    "# How many instances have we got?\n",
    "print('# instances in training set: ', len(train_data))\n",
    "print('# instances in validation set: ', len(val_data))\n",
    "print('# instances in testing set: ', len(test_data))\n",
    "\n",
    "batch_size = 64\n",
    "\n",
    "# Create the dataloaders - for training, validation and testing\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_data, batch_size=batch_size, shuffle=True)\n",
    "valid_loader = torch.utils.data.DataLoader(dataset=val_data, batch_size=batch_size, shuffle=True)\n",
    "test_loader  = torch.utils.data.DataLoader(dataset=test_data, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train_data.features\n",
    "#y_train = pd.DataFrame(train_data.labels)\n",
    "X_val = val_data.features\n",
    "#y_val = pd.DataFrame(val_data.labels)\n",
    "X_test = test_data.features\n",
    "#y_test = pd.DataFrame(test_data.labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = train_data.labels\n",
    "y_val = val_data.labels\n",
    "y_test = test_data.labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test = y_test.squeeze()\n",
    "y_val = y_val.squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((140000, 1, 49), (485145, 1, 49))"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#reshape the data for CNN pytorch\n",
    "X_train = X_train.to_numpy().reshape(len(X_train), 1, X_train.shape[1])\n",
    "X_val = X_val.to_numpy().reshape(len(X_val), 1, X_val.shape[1])\n",
    "X_test = X_test.to_numpy().reshape(len(X_test), 1, X_test.shape[1])\n",
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[[0.18218218, 0.42792793, 0.73973974, ..., 0.        ,\n",
       "          0.        , 0.        ]],\n",
       " \n",
       "        [[0.18218218, 0.5005005 , 0.8018018 , ..., 0.        ,\n",
       "          0.        , 0.        ]],\n",
       " \n",
       "        [[0.68818819, 0.74474474, 0.        , ..., 0.96613885,\n",
       "          0.90740741, 0.91591592]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[0.80272778, 0.20820821, 0.57207207, ..., 0.        ,\n",
       "          0.        , 0.        ]],\n",
       " \n",
       "        [[0.82282282, 0.72722723, 0.        , ..., 0.        ,\n",
       "          0.        , 0.        ]],\n",
       " \n",
       "        [[0.90712836, 0.20820821, 0.57207207, ..., 0.        ,\n",
       "          0.        , 0.        ]]]),\n",
       " 623961     0\n",
       " 393314     0\n",
       " 624080     0\n",
       " 1430553    0\n",
       " 636972     0\n",
       "           ..\n",
       " 259700     1\n",
       " 757698     1\n",
       " 521547     1\n",
       " 1447653    1\n",
       " 94017      1\n",
       " Name: label, Length: 140000, dtype: int64)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create model\n",
    "class CNN2ID(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN2ID, self).__init__()\n",
    "        self.conv1 = nn.Conv1d(in_channels = 1, out_channels=64, kernel_size=5, padding=2)\n",
    "        self.batchnorm1 = nn.BatchNorm1d(64)\n",
    "        self.maxpool1 = nn.MaxPool1d(kernel_size=3, stride=2, padding=1)\n",
    "        self.conv2 = nn.Conv1d(in_channels = 64, out_channels=64, kernel_size=5, padding=2)\n",
    "        self.batchnorm2 = nn.BatchNorm1d(64)\n",
    "        self.maxpool2 = nn.MaxPool1d(kernel_size=3, stride=2, padding=1)\n",
    "        self.conv3 = nn.Conv1d(in_channels = 64, out_channels=64, kernel_size=5, padding=2)\n",
    "        self.batchnorm3 = nn.BatchNorm1d(64)\n",
    "        self.maxpool3 = nn.MaxPool1d(kernel_size=3, stride=2, padding=1)\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.fc1 = nn.Linear(7*64, 64)#应该是这里的问题\n",
    "        self.fc2 = nn.Linear(64, 64)\n",
    "        self.fc3 = nn.Linear(64, 7)#64, 3\n",
    "        \n",
    "        self.relu = nn.ReLU()\n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.relu(self.conv1(x))\n",
    "        x = self.batchnorm1(x)\n",
    "        x = self.maxpool1(x)\n",
    "        \n",
    "        x = self.relu(self.conv2(x))\n",
    "        x = self.batchnorm2(x)\n",
    "        x = self.maxpool2(x)\n",
    "        \n",
    "        x = self.relu(self.conv3(x))\n",
    "        x = self.batchnorm3(x)\n",
    "        x = self.maxpool3(x)\n",
    "        \n",
    "        x = self.flatten(x)\n",
    "        x = self.relu(self.fc1(x))\n",
    "        x = self.relu(self.fc2(x))\n",
    "        x = self.softmax(self.fc3(x))\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_data = torch.randn((32, 1, 49))\n",
    "model = CNN2ID()\n",
    "output = model(input_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape: torch.Size([32, 1, 49])\n",
      "Conv1 output shape: torch.Size([32, 64, 49])\n",
      "BatchNorm1 output shape: torch.Size([32, 64, 49])\n",
      "MaxPool1 output shape: torch.Size([32, 64, 25])\n",
      "Conv2 output shape: torch.Size([32, 64, 25])\n",
      "BatchNorm2 output shape: torch.Size([32, 64, 25])\n",
      "MaxPool2 output shape: torch.Size([32, 64, 13])\n",
      "Conv3 output shape: torch.Size([32, 64, 13])\n",
      "BatchNorm3 output shape: torch.Size([32, 64, 13])\n",
      "MaxPool3 output shape: torch.Size([32, 64, 7])\n",
      "Flatten output shape: torch.Size([32, 448])\n",
      "FC1 output shape: torch.Size([32, 64])\n",
      "FC2 output shape: torch.Size([32, 64])\n",
      "FC3 output shape: torch.Size([32, 7])\n",
      "Output shape: torch.Size([32, 7])\n"
     ]
    }
   ],
   "source": [
    "input_data = torch.randn((32, 1, 49))\n",
    "model = CNN2ID()\n",
    "\n",
    "# 逐层计算形状变化\n",
    "print(\"Input shape:\", input_data.shape)\n",
    "\n",
    "x = model.conv1(input_data)\n",
    "print(\"Conv1 output shape:\", x.shape)\n",
    "\n",
    "x = model.batchnorm1(x)\n",
    "print(\"BatchNorm1 output shape:\", x.shape)\n",
    "\n",
    "x = model.maxpool1(x)\n",
    "print(\"MaxPool1 output shape:\", x.shape)\n",
    "\n",
    "x = model.conv2(x)\n",
    "print(\"Conv2 output shape:\", x.shape)\n",
    "\n",
    "x = model.batchnorm2(x)\n",
    "print(\"BatchNorm2 output shape:\", x.shape)\n",
    "\n",
    "x = model.maxpool2(x)\n",
    "print(\"MaxPool2 output shape:\", x.shape)\n",
    "\n",
    "x = model.conv3(x)\n",
    "print(\"Conv3 output shape:\", x.shape)\n",
    "\n",
    "x = model.batchnorm3(x)\n",
    "print(\"BatchNorm3 output shape:\", x.shape)\n",
    "\n",
    "x = model.maxpool3(x)\n",
    "print(\"MaxPool3 output shape:\", x.shape)\n",
    "\n",
    "x = model.flatten(x)\n",
    "print(\"Flatten output shape:\", x.shape)\n",
    "\n",
    "x = model.fc1(x)\n",
    "print(\"FC1 output shape:\", x.shape)\n",
    "\n",
    "x = model.fc2(x)\n",
    "print(\"FC2 output shape:\", x.shape)\n",
    "\n",
    "x = model.fc3(x)\n",
    "print(\"FC3 output shape:\", x.shape)\n",
    "\n",
    "output = model.softmax(x)\n",
    "print(\"Output shape:\", output.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 训练过程\n",
    "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "def train(model, criterion, optimizer, X_train, y_train, epochs, batch_size):\n",
    "    model.train()  # 设置模型为训练模式\n",
    "    num_samples = X_train.shape[0]\n",
    "    #y_train = y_train.squeeze()\n",
    "    #num_batches = num_samples // batch_size\n",
    "    y_train = np.array(y_train)\n",
    "\n",
    "    for batch in range(num_samples // batch_size):\n",
    "        start_index = batch * batch_size\n",
    "        end_index = (batch + 1) * batch_size\n",
    "        inputs = torch.tensor(X_train[start_index:end_index], dtype=torch.float32)\n",
    "        labels = torch.tensor(y_train[start_index:end_index], dtype=torch.long)\n",
    "\n",
    "        optimizer.zero_grad()  # 梯度清零\n",
    "\n",
    "        outputs = model(inputs)  # 前向传播\n",
    "        loss = criterion(outputs, labels)  # 计算损失\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "        acc = torch.sum(preds ==labels.data) / labels.size(0)\n",
    "        loss.backward()  # 反向传播\n",
    "        optimizer.step()  # 更新参数\n",
    "            \n",
    "        \n",
    "        #print(f\"Epoch {epoch+1}/{epochs}, Loss: {epoch_loss/num_batches:.4f}\")\n",
    "        return loss, acc\n",
    "#定义验证函数\n",
    "def validate(model, criterion, X_test, y_test, epochs, batch_size):\n",
    "    model.eval()  # 设置模型为评估模式\n",
    "    epoch_loss = 0.0\n",
    "    epoch_acc = 0.0\n",
    "    y_test = np.array(y_test)\n",
    "    with torch.no_grad():\n",
    "        for batch in range(X_test.shape[0] // batch_size):\n",
    "            start_index = batch * batch_size\n",
    "            end_index = (batch + 1) * batch_size\n",
    "            inputs = torch.tensor(X_test[start_index:end_index], dtype=torch.float32)\n",
    "            labels = torch.tensor(y_test[start_index:end_index], dtype=torch.long)\n",
    "\n",
    "            outputs = model(inputs)  # 前向传播\n",
    "            loss = criterion(outputs, labels)  # 计算损失\n",
    "            _, preds = torch.max(outputs, 1)  # 预测结果\n",
    "            acc = torch.sum(preds == labels.data) / labels.size(0)  # 计算准确率\n",
    "\n",
    "            epoch_loss += loss.item() * inputs.size(0)\n",
    "            epoch_acc += acc.item() * inputs.size(0)\n",
    "\n",
    "    epoch_loss /= X_test.shape[0]\n",
    "    epoch_acc /= X_test.shape[0]\n",
    "    return epoch_loss, epoch_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss: 1.9398, Val Acc: 0.0010\n",
      "Epoch 1/80\n",
      "Train Loss: 1.9349, Train Acc: 0.0312\n",
      "Epoch 2/80\n",
      "Train Loss: 1.8649, Train Acc: 1.0000\n",
      "Epoch 3/80\n",
      "Train Loss: 1.7849, Train Acc: 1.0000\n",
      "Epoch 4/80\n",
      "Train Loss: 1.6839, Train Acc: 1.0000\n",
      "Epoch 5/80\n",
      "Train Loss: 1.5646, Train Acc: 1.0000\n",
      "Epoch 6/80\n",
      "Train Loss: 1.4416, Train Acc: 1.0000\n",
      "Epoch 7/80\n",
      "Train Loss: 1.3358, Train Acc: 1.0000\n",
      "Epoch 8/80\n",
      "Train Loss: 1.2590, Train Acc: 1.0000\n",
      "Epoch 9/80\n",
      "Train Loss: 1.2111, Train Acc: 1.0000\n",
      "Epoch 10/80\n",
      "Train Loss: 1.1858, Train Acc: 1.0000\n",
      "Val Loss: 1.9187, Val Acc: 0.6035\n",
      "Epoch 11/80\n",
      "Train Loss: 1.1740, Train Acc: 1.0000\n",
      "Epoch 12/80\n",
      "Train Loss: 1.1690, Train Acc: 1.0000\n",
      "Epoch 13/80\n",
      "Train Loss: 1.1669, Train Acc: 1.0000\n",
      "Epoch 14/80\n",
      "Train Loss: 1.1661, Train Acc: 1.0000\n",
      "Epoch 15/80\n",
      "Train Loss: 1.1657, Train Acc: 1.0000\n",
      "Epoch 16/80\n",
      "Train Loss: 1.1656, Train Acc: 1.0000\n",
      "Epoch 17/80\n",
      "Train Loss: 1.1655, Train Acc: 1.0000\n",
      "Epoch 18/80\n",
      "Train Loss: 1.1655, Train Acc: 1.0000\n",
      "Epoch 19/80\n",
      "Train Loss: 1.1654, Train Acc: 1.0000\n",
      "Epoch 20/80\n",
      "Train Loss: 1.1654, Train Acc: 1.0000\n",
      "Val Loss: 1.6877, Val Acc: 0.8391\n",
      "Epoch 21/80\n",
      "Train Loss: 1.1654, Train Acc: 1.0000\n",
      "Epoch 22/80\n",
      "Train Loss: 1.1654, Train Acc: 1.0000\n",
      "Epoch 23/80\n",
      "Train Loss: 1.1654, Train Acc: 1.0000\n",
      "Epoch 24/80\n",
      "Train Loss: 1.1654, Train Acc: 1.0000\n",
      "Epoch 25/80\n",
      "Train Loss: 1.1654, Train Acc: 1.0000\n",
      "Epoch 26/80\n",
      "Train Loss: 1.1654, Train Acc: 1.0000\n",
      "Epoch 27/80\n",
      "Train Loss: 1.1654, Train Acc: 1.0000\n",
      "Epoch 28/80\n",
      "Train Loss: 1.1654, Train Acc: 1.0000\n",
      "Epoch 29/80\n",
      "Train Loss: 1.1654, Train Acc: 1.0000\n",
      "Epoch 30/80\n",
      "Train Loss: 1.1654, Train Acc: 1.0000\n",
      "Val Loss: 1.3507, Val Acc: 0.8391\n",
      "Epoch 31/80\n",
      "Train Loss: 1.1654, Train Acc: 1.0000\n",
      "Epoch 32/80\n",
      "Train Loss: 1.1654, Train Acc: 1.0000\n",
      "Epoch 33/80\n",
      "Train Loss: 1.1654, Train Acc: 1.0000\n",
      "Epoch 34/80\n",
      "Train Loss: 1.1654, Train Acc: 1.0000\n",
      "Epoch 35/80\n",
      "Train Loss: 1.1654, Train Acc: 1.0000\n",
      "Epoch 36/80\n",
      "Train Loss: 1.1654, Train Acc: 1.0000\n",
      "Epoch 37/80\n",
      "Train Loss: 1.1654, Train Acc: 1.0000\n",
      "Epoch 38/80\n",
      "Train Loss: 1.1654, Train Acc: 1.0000\n",
      "Epoch 39/80\n",
      "Train Loss: 1.1654, Train Acc: 1.0000\n",
      "Epoch 40/80\n",
      "Train Loss: 1.1654, Train Acc: 1.0000\n",
      "Val Loss: 1.3268, Val Acc: 0.8391\n",
      "Epoch 41/80\n",
      "Train Loss: 1.1654, Train Acc: 1.0000\n",
      "Epoch 42/80\n",
      "Train Loss: 1.1654, Train Acc: 1.0000\n",
      "Epoch 43/80\n",
      "Train Loss: 1.1654, Train Acc: 1.0000\n",
      "Epoch 44/80\n",
      "Train Loss: 1.1654, Train Acc: 1.0000\n",
      "Epoch 45/80\n",
      "Train Loss: 1.1654, Train Acc: 1.0000\n",
      "Epoch 46/80\n",
      "Train Loss: 1.1654, Train Acc: 1.0000\n",
      "Epoch 47/80\n",
      "Train Loss: 1.1654, Train Acc: 1.0000\n",
      "Epoch 48/80\n",
      "Train Loss: 1.1654, Train Acc: 1.0000\n",
      "Epoch 49/80\n",
      "Train Loss: 1.1654, Train Acc: 1.0000\n",
      "Epoch 50/80\n",
      "Train Loss: 1.1654, Train Acc: 1.0000\n",
      "Val Loss: 1.3262, Val Acc: 0.8391\n",
      "Epoch 51/80\n",
      "Train Loss: 1.1654, Train Acc: 1.0000\n",
      "Epoch 52/80\n",
      "Train Loss: 1.1654, Train Acc: 1.0000\n",
      "Epoch 53/80\n",
      "Train Loss: 1.1654, Train Acc: 1.0000\n",
      "Epoch 54/80\n",
      "Train Loss: 1.1654, Train Acc: 1.0000\n",
      "Epoch 55/80\n",
      "Train Loss: 1.1654, Train Acc: 1.0000\n",
      "Epoch 56/80\n",
      "Train Loss: 1.1654, Train Acc: 1.0000\n",
      "Epoch 57/80\n",
      "Train Loss: 1.1654, Train Acc: 1.0000\n",
      "Epoch 58/80\n",
      "Train Loss: 1.1654, Train Acc: 1.0000\n",
      "Epoch 59/80\n",
      "Train Loss: 1.1654, Train Acc: 1.0000\n",
      "Epoch 60/80\n",
      "Train Loss: 1.1654, Train Acc: 1.0000\n",
      "Val Loss: 1.3262, Val Acc: 0.8391\n",
      "Epoch 61/80\n",
      "Train Loss: 1.1654, Train Acc: 1.0000\n",
      "Epoch 62/80\n",
      "Train Loss: 1.1654, Train Acc: 1.0000\n",
      "Epoch 63/80\n",
      "Train Loss: 1.1654, Train Acc: 1.0000\n",
      "Epoch 64/80\n",
      "Train Loss: 1.1654, Train Acc: 1.0000\n",
      "Epoch 65/80\n",
      "Train Loss: 1.1654, Train Acc: 1.0000\n",
      "Epoch 66/80\n",
      "Train Loss: 1.1654, Train Acc: 1.0000\n",
      "Epoch 67/80\n",
      "Train Loss: 1.1654, Train Acc: 1.0000\n",
      "Epoch 68/80\n",
      "Train Loss: 1.1654, Train Acc: 1.0000\n",
      "Epoch 69/80\n",
      "Train Loss: 1.1654, Train Acc: 1.0000\n",
      "Epoch 70/80\n",
      "Train Loss: 1.1654, Train Acc: 1.0000\n",
      "Val Loss: 1.3262, Val Acc: 0.8391\n",
      "Epoch 71/80\n",
      "Train Loss: 1.1654, Train Acc: 1.0000\n",
      "Epoch 72/80\n",
      "Train Loss: 1.1654, Train Acc: 1.0000\n",
      "Epoch 73/80\n",
      "Train Loss: 1.1654, Train Acc: 1.0000\n",
      "Epoch 74/80\n",
      "Train Loss: 1.1654, Train Acc: 1.0000\n",
      "Epoch 75/80\n",
      "Train Loss: 1.1654, Train Acc: 1.0000\n",
      "Epoch 76/80\n",
      "Train Loss: 1.1654, Train Acc: 1.0000\n",
      "Epoch 77/80\n",
      "Train Loss: 1.1654, Train Acc: 1.0000\n",
      "Epoch 78/80\n",
      "Train Loss: 1.1654, Train Acc: 1.0000\n",
      "Epoch 79/80\n",
      "Train Loss: 1.1654, Train Acc: 1.0000\n",
      "Epoch 80/80\n",
      "Train Loss: 1.1654, Train Acc: 1.0000\n"
     ]
    }
   ],
   "source": [
    "#主函数\n",
    "epochs = 80\n",
    "batch_size = 128\n",
    "learning_rate = 0.001\n",
    "\n",
    "#定义模型    \n",
    "model = CNN2ID()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "val_interval = 10#每10次\n",
    "#训练\n",
    "for epoch in range(epochs):\n",
    "    #训练，调用train函数 X_train, y_train\n",
    "    train_loss, train_acc = train(model, criterion, optimizer, X_train, y_train, epochs, batch_size)\n",
    "    #验证，调用val函数 X_test, y_test\n",
    "    if epoch%val_interval == 0:\n",
    "        val_loss, val_acc = validate(model, criterion, X_test, y_test, epochs, batch_size)\n",
    "        print(f\"Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.4f}\")\n",
    "    #输出结果\n",
    "    print(f\"Epoch {epoch+1}/{epochs}\")\n",
    "    print(f\"Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.4f}\")\n",
    "    #print(f\"Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, criterion, optimizer, X_train, y_train, epochs, batch_size):\n",
    "    model.train()  # 设置模型为训练模式\n",
    "    num_samples = X_train.shape[0]\n",
    "    y_train = np.array(y_train)\n",
    "    train_loss = 0.0\n",
    "    train_acc = 0.0\n",
    "    train_correct = 0\n",
    "    num_batches = 0\n",
    "\n",
    "    for batch in range(num_samples // batch_size):\n",
    "        start_index = batch * batch_size\n",
    "        end_index = (batch + 1) * batch_size\n",
    "        inputs = torch.tensor(X_train[start_index:end_index], dtype=torch.float32)\n",
    "        labels = torch.tensor(y_train[start_index:end_index], dtype=torch.long)\n",
    "\n",
    "        optimizer.zero_grad()  # 梯度清零\n",
    "\n",
    "        outputs = model(inputs)  # 前向传播\n",
    "        loss = criterion(outputs, labels)  # 计算损失\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "        #acc = torch.sum(preds == labels.data) / labels.size(0)\n",
    "\n",
    "        loss.backward()  # 反向传播\n",
    "        optimizer.step()  # 更新参数\n",
    "        correct = (preds == labels).sum().item()\n",
    "        train_correct += correct\n",
    "        train_loss += loss.item()  # 累积损失\n",
    "        #train_acc += acc.item()  # 累积准确率\n",
    "        num_batches += 1\n",
    "\n",
    "    # 计算平均损失和准确率\n",
    "    train_loss /= num_batches\n",
    "    train_acc = train_correct/num_samples\n",
    "\n",
    "    return train_loss, train_acc"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env02",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
